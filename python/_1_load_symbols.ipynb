{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df6e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.11 (dt dec pq3 ext lo64)\n",
      "2.3.3\n",
      "2.32.5\n",
      "1.0\n",
      "0.2.66\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "print(psycopg2.__version__)\n",
    "print(pd.__version__)\n",
    "print(requests.__version__)\n",
    "print(csv.__version__)\n",
    "print(yf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4859ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Database connection parameters\n",
    "db_host = \"localhost\"\n",
    "db_name = \"bootcamp_2508_final_project\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"admin1234\"\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")\n",
    "\n",
    "# URL of the CSV file\n",
    "url = \"https://raw.githubusercontent.com/datasets/s-and-p-500-companies/refs/heads/main/data/constituents.csv\"\n",
    "\n",
    "\n",
    "# Fetch the CSV data\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "   # Decode the content and split into lines\n",
    "   content = response.content.decode('utf-8').splitlines()\n",
    "    \n",
    "# Read the CSV data\n",
    "reader = csv.reader(content)\n",
    "next(reader)  # Skip the header row\n",
    "\n",
    "# Extract symbols and write to a .txt file\n",
    "with open(\"sp500_symbols.txt\", \"w\") as file:\n",
    "  for row in reader:\n",
    "      symbol = row[0]  # The first column contains the symbol\n",
    "      file.write(symbol + \"\\n\")\n",
    "      print(f\"{symbol} have been saved to sp500_symbols.txt.\")\n",
    "  else:\n",
    "      print(\"Failed to fetch data:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ce47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 symbols have been stored in the PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "\n",
    "# Database connection parameters\n",
    "db_host = \"localhost\"\n",
    "db_name = \"bootcamp_2508_final_project\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"admin1234\"\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sp500_symbols (\n",
    "    symbol VARCHAR(10) primary key NOT NULL UNIQUE,\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Open the file and read symbols\n",
    "with open(\"sp500_symbols.txt\", \"r\") as file:\n",
    "    symbols = file.readlines()\n",
    "\n",
    "# Insert symbols into the database\n",
    "for symbol in symbols:\n",
    "    symbol = symbol.strip()  # Remove any whitespace/newline characters\n",
    "    try:\n",
    "        cursor.execute(\"INSERT INTO sp500_symbols (symbol) VALUES (%s) ON CONFLICT (symbol) DO NOTHING;\", (symbol,))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting {symbol}: {e}\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"S&P 500 symbols have been stored in the PostgreSQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81aaf637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows & columns have been saved to sp500_information.txt.\n",
      "S&P 500 companies have been stored in the PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Database connection parameters\n",
    "db_host = \"localhost\"\n",
    "db_name = \"bootcamp_2508_final_project\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"admin1234\"\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "create_table_query = \"\"\"\n",
    "create table IF NOT EXISTS sp500_info (\n",
    "    symbol VARCHAR(10) primary key NOT NULL UNIQUE,\n",
    "    security VARCHAR(255) NOT NULL,\n",
    "    gics_sector VARCHAR(255) NOT NULL,\n",
    "    gics_sub_industry VARCHAR(255) NOT NULL,\n",
    "    headquarters_location VARCHAR(255) NOT NULL,\n",
    "    date_added DATE NOT NULL,\n",
    "    cik VARCHAR(20) NOT NULL,\n",
    "    founded TEXT NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Load CSV data from URL\n",
    "url = 'https://raw.githubusercontent.com/datasets/s-and-p-500-companies/refs/heads/main/data/constituents.csv'\n",
    "# Fetch the CSV data\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open a CSV file and read data\n",
    "    # Decode the content and split into lines\n",
    "    lines = response.content.decode('utf-8').splitlines()\n",
    "    # Read the CSV data\n",
    "    reader = csv.reader(lines)\n",
    "    header = next(reader)  # Get the header row\n",
    "\n",
    "    # Extract symbols and write to a .txt file\n",
    "    with open(\"sp500_information.txt\", \"w\", newline='', encoding='utf-8') as txt_file:\n",
    "        # Optional: write the header as a comment line\n",
    "        txt_file.write(\"# \" + \",\".join(header) + \"\\n\")\n",
    "\n",
    "        for row in reader:\n",
    "            # Write the full row as a CSV line (comma-separated)\n",
    "            txt_file.write(\",\".join(row) + \"\\n\")\n",
    "\n",
    "    print(\"All rows & columns have been saved to sp500_information.txt.\")\n",
    "else:\n",
    "    print(\"Failed to fetch data:\", response.status_code)\n",
    "\n",
    "# Re-open the same data for DB insertion (re-use the same reader)\n",
    "    # Reset the reader because we already consumed it above\n",
    "lines = response.content.decode('utf-8').splitlines()\n",
    "reader = csv.reader(lines)\n",
    "next(reader)   # skip header again\n",
    "\n",
    "# Insert data into the database\n",
    "for row in reader:\n",
    "    # Convert date from string to date object\n",
    "    date_added = datetime.strptime(row[5], '%Y-%m-%d').date()\n",
    "    \n",
    "    # Clean the founded value\n",
    "    founded_cleaned = re.sub(r'\\s*\\(.*\\)', '', row[7])  # Remove anything in parentheses\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO sp500_info (symbol, security, gics_sector, gics_sub_industry, headquarters_location, date_added, cik, founded)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (symbol) DO NOTHING;\n",
    "    \"\"\", (row[0], row[1], row[2], row[3], row[4], date_added, row[6], founded_cleaned))\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"S&P 500 companies have been stored in the PostgreSQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759c808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 10:27:55,323 | INFO | Loaded 503 symbols\n",
      "2025-10-30 10:27:55,325 | INFO | Starting fetch → saving to C:\\github\\Bootcamp-Final-Project\\python\\sp500_finnhub_profiles.json\n",
      "2025-10-30 10:27:55,329 | INFO | [1/503] Fetching MMM\n",
      "2025-10-30 10:27:57,303 | INFO | [2/503] Fetching AOS\n",
      "2025-10-30 10:27:59,007 | INFO | [3/503] Fetching ABT\n",
      "2025-10-30 10:28:00,709 | INFO | [4/503] Fetching ABBV\n",
      "2025-10-30 10:28:02,459 | INFO | [5/503] Fetching ACN\n",
      "2025-10-30 10:28:04,365 | INFO | [6/503] Fetching ADBE\n",
      "2025-10-30 10:28:06,146 | INFO | [7/503] Fetching AMD\n",
      "2025-10-30 10:28:07,948 | INFO | [8/503] Fetching AES\n",
      "2025-10-30 10:28:09,727 | INFO | [9/503] Fetching AFL\n",
      "2025-10-30 10:28:11,532 | INFO | [10/503] Fetching A\n",
      "2025-10-30 10:28:13,271 | INFO | [11/503] Fetching APD\n",
      "2025-10-30 10:28:14,952 | INFO | [12/503] Fetching ABNB\n",
      "2025-10-30 10:28:16,870 | INFO | [13/503] Fetching AKAM\n",
      "2025-10-30 10:28:18,799 | INFO | [14/503] Fetching ALB\n",
      "2025-10-30 10:28:20,650 | INFO | [15/503] Fetching ARE\n",
      "2025-10-30 10:28:22,486 | INFO | [16/503] Fetching ALGN\n",
      "2025-10-30 10:28:24,324 | INFO | [17/503] Fetching ALLE\n",
      "2025-10-30 10:28:26,012 | INFO | [18/503] Fetching LNT\n",
      "2025-10-30 10:28:27,908 | INFO | [19/503] Fetching ALL\n",
      "2025-10-30 10:28:29,699 | INFO | [20/503] Fetching GOOGL\n",
      "2025-10-30 10:28:31,478 | INFO | [21/503] Fetching GOOG\n",
      "2025-10-30 10:28:33,236 | INFO | [22/503] Fetching MO\n",
      "2025-10-30 10:28:35,025 | INFO | [23/503] Fetching AMZN\n",
      "2025-10-30 10:28:36,766 | INFO | [24/503] Fetching AMCR\n",
      "2025-10-30 10:28:38,568 | INFO | [25/503] Fetching AEE\n",
      "2025-10-30 10:28:40,472 | INFO | [26/503] Fetching AEP\n",
      "2025-10-30 10:28:42,242 | INFO | [27/503] Fetching AXP\n",
      "2025-10-30 10:28:43,932 | INFO | [28/503] Fetching AIG\n",
      "2025-10-30 10:28:45,727 | INFO | [29/503] Fetching AMT\n",
      "2025-10-30 10:28:47,415 | INFO | [30/503] Fetching AWK\n",
      "2025-10-30 10:28:49,218 | INFO | [31/503] Fetching AMP\n",
      "2025-10-30 10:28:51,002 | INFO | [32/503] Fetching AME\n",
      "2025-10-30 10:28:52,730 | INFO | [33/503] Fetching AMGN\n",
      "2025-10-30 10:28:54,536 | INFO | [34/503] Fetching APH\n",
      "2025-10-30 10:28:56,381 | INFO | [35/503] Fetching ADI\n",
      "2025-10-30 10:28:58,168 | INFO | [36/503] Fetching AON\n",
      "2025-10-30 10:28:59,908 | INFO | [37/503] Fetching APA\n",
      "2025-10-30 10:29:01,754 | INFO | [38/503] Fetching APO\n",
      "2025-10-30 10:29:03,651 | INFO | [39/503] Fetching AAPL\n",
      "2025-10-30 10:29:05,501 | INFO | [40/503] Fetching AMAT\n",
      "2025-10-30 10:29:07,278 | INFO | [41/503] Fetching APTV\n",
      "2025-10-30 10:29:09,020 | INFO | [42/503] Fetching ACGL\n",
      "2025-10-30 10:29:11,015 | INFO | [43/503] Fetching ADM\n",
      "2025-10-30 10:29:12,880 | INFO | [44/503] Fetching ANET\n",
      "2025-10-30 10:29:14,697 | INFO | [45/503] Fetching AJG\n",
      "2025-10-30 10:29:16,444 | INFO | [46/503] Fetching AIZ\n",
      "2025-10-30 10:29:18,294 | INFO | [47/503] Fetching T\n",
      "2025-10-30 10:29:19,945 | INFO | [48/503] Fetching ATO\n",
      "2025-10-30 10:29:21,776 | INFO | [49/503] Fetching ADSK\n",
      "2025-10-30 10:29:23,616 | INFO | [50/503] Fetching ADP\n",
      "2025-10-30 10:29:25,405 | INFO | [51/503] Fetching AZO\n",
      "2025-10-30 10:29:27,197 | INFO | [52/503] Fetching AVB\n",
      "2025-10-30 10:29:29,047 | INFO | [53/503] Fetching AVY\n",
      "2025-10-30 10:29:30,783 | INFO | [54/503] Fetching AXON\n",
      "2025-10-30 10:29:32,632 | INFO | [55/503] Fetching BKR\n",
      "2025-10-30 10:29:34,444 | INFO | [56/503] Fetching BALL\n",
      "2025-10-30 10:29:36,147 | INFO | [57/503] Fetching BAC\n",
      "2025-10-30 10:29:37,948 | INFO | [58/503] Fetching BAX\n",
      "2025-10-30 10:29:39,641 | INFO | [59/503] Fetching BDX\n",
      "2025-10-30 10:29:41,482 | INFO | [60/503] Fetching BRK.B\n",
      "2025-10-30 10:29:43,279 | INFO | [61/503] Fetching BBY\n",
      "2025-10-30 10:29:45,129 | INFO | [62/503] Fetching TECH\n",
      "2025-10-30 10:29:46,964 | INFO | [63/503] Fetching BIIB\n",
      "2025-10-30 10:29:48,713 | INFO | [64/503] Fetching BLK\n",
      "2025-10-30 10:29:50,427 | INFO | [65/503] Fetching BX\n",
      "2025-10-30 10:29:52,164 | INFO | [66/503] Fetching XYZ\n",
      "2025-10-30 10:29:53,867 | INFO | [67/503] Fetching BK\n",
      "2025-10-30 10:29:55,823 | INFO | [68/503] Fetching BA\n",
      "2025-10-30 10:29:57,562 | INFO | [69/503] Fetching BKNG\n",
      "2025-10-30 10:29:59,381 | INFO | [70/503] Fetching BSX\n",
      "2025-10-30 10:30:01,193 | INFO | [71/503] Fetching BMY\n",
      "2025-10-30 10:30:02,883 | INFO | [72/503] Fetching AVGO\n",
      "2025-10-30 10:30:04,582 | INFO | [73/503] Fetching BR\n",
      "2025-10-30 10:30:06,262 | INFO | [74/503] Fetching BRO\n",
      "2025-10-30 10:30:07,964 | INFO | [75/503] Fetching BF.B\n",
      "2025-10-30 10:30:09,695 | INFO | [76/503] Fetching BLDR\n",
      "2025-10-30 10:30:11,439 | INFO | [77/503] Fetching BG\n",
      "2025-10-30 10:30:13,281 | INFO | [78/503] Fetching BXP\n",
      "2025-10-30 10:30:15,026 | INFO | [79/503] Fetching CHRW\n",
      "2025-10-30 10:30:16,767 | INFO | [80/503] Fetching CDNS\n",
      "2025-10-30 10:30:18,714 | INFO | [81/503] Fetching CZR\n",
      "2025-10-30 10:30:20,356 | INFO | [82/503] Fetching CPT\n",
      "2025-10-30 10:30:22,056 | INFO | [83/503] Fetching CPB\n",
      "2025-10-30 10:30:23,773 | INFO | [84/503] Fetching COF\n",
      "2025-10-30 10:30:25,581 | INFO | [85/503] Fetching CAH\n",
      "2025-10-30 10:30:27,326 | INFO | [86/503] Fetching KMX\n",
      "2025-10-30 10:30:29,150 | INFO | [87/503] Fetching CCL\n",
      "2025-10-30 10:30:30,997 | INFO | [88/503] Fetching CARR\n",
      "2025-10-30 10:30:32,748 | INFO | [89/503] Fetching CAT\n",
      "2025-10-30 10:30:34,466 | INFO | [90/503] Fetching CBOE\n",
      "2025-10-30 10:30:36,328 | INFO | [91/503] Fetching CBRE\n",
      "2025-10-30 10:30:38,054 | INFO | [92/503] Fetching CDW\n",
      "2025-10-30 10:36:24,742 | INFO | [93/503] Fetching COR\n",
      "2025-10-30 10:36:24,762 | ERROR | Error COR: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=COR&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002204BF07B10>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 10:36:25,863 | INFO | [94/503] Fetching CNC\n",
      "2025-10-30 10:36:27,928 | INFO | [95/503] Fetching CNP\n",
      "2025-10-30 10:36:29,593 | INFO | [96/503] Fetching CF\n",
      "2025-10-30 10:36:31,493 | INFO | [97/503] Fetching CRL\n",
      "2025-10-30 10:36:33,246 | INFO | [98/503] Fetching SCHW\n",
      "2025-10-30 10:36:35,283 | INFO | [99/503] Fetching CHTR\n",
      "2025-10-30 10:36:37,543 | INFO | [100/503] Fetching CVX\n",
      "2025-10-30 10:36:39,630 | INFO | [101/503] Fetching CMG\n",
      "2025-10-30 10:36:41,633 | INFO | [102/503] Fetching CB\n",
      "2025-10-30 10:36:43,578 | INFO | [103/503] Fetching CHD\n",
      "2025-10-30 10:36:45,477 | INFO | [104/503] Fetching CI\n",
      "2025-10-30 10:36:47,328 | INFO | [105/503] Fetching CINF\n",
      "2025-10-30 10:36:49,314 | INFO | [106/503] Fetching CTAS\n",
      "2025-10-30 10:36:51,258 | INFO | [107/503] Fetching CSCO\n",
      "2025-10-30 10:36:52,883 | INFO | [108/503] Fetching C\n",
      "2025-10-30 10:36:54,638 | INFO | [109/503] Fetching CFG\n",
      "2025-10-30 10:36:56,306 | INFO | [110/503] Fetching CLX\n",
      "2025-10-30 10:36:58,175 | INFO | [111/503] Fetching CME\n",
      "2025-10-30 10:37:00,167 | INFO | [112/503] Fetching CMS\n",
      "2025-10-30 10:37:02,063 | INFO | [113/503] Fetching KO\n",
      "2025-10-30 10:37:03,916 | INFO | [114/503] Fetching CTSH\n",
      "2025-10-30 10:37:06,004 | INFO | [115/503] Fetching COIN\n",
      "2025-10-30 10:37:07,846 | INFO | [116/503] Fetching CL\n",
      "2025-10-30 10:37:09,793 | INFO | [117/503] Fetching CMCSA\n",
      "2025-10-30 10:37:11,637 | INFO | [118/503] Fetching CAG\n",
      "2025-10-30 10:37:13,537 | INFO | [119/503] Fetching COP\n",
      "2025-10-30 10:37:15,311 | INFO | [120/503] Fetching ED\n",
      "2025-10-30 10:37:17,166 | INFO | [121/503] Fetching STZ\n",
      "2025-10-30 10:37:18,967 | INFO | [122/503] Fetching CEG\n",
      "2025-10-30 10:46:05,128 | ERROR | Error CEG: ('Connection aborted.', ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 10:46:06,230 | INFO | [123/503] Fetching COO\n",
      "2025-10-30 10:46:06,341 | ERROR | Error COO: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=COO&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2CB90>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 10:46:07,442 | INFO | [124/503] Fetching CPRT\n",
      "2025-10-30 10:46:19,813 | ERROR | Error CPRT: HTTPSConnectionPool(host='finnhub.io', port=443): Read timed out. (read timeout=12)\n",
      "2025-10-30 10:46:20,915 | INFO | [125/503] Fetching GLW\n",
      "2025-10-30 10:46:23,016 | INFO | [126/503] Fetching CPAY\n",
      "2025-10-30 10:46:24,707 | INFO | [127/503] Fetching CTVA\n",
      "2025-10-30 10:46:26,495 | INFO | [128/503] Fetching CSGP\n",
      "2025-10-30 10:46:28,187 | INFO | [129/503] Fetching COST\n",
      "2025-10-30 10:46:29,992 | INFO | [130/503] Fetching CTRA\n",
      "2025-10-30 10:46:31,723 | INFO | [131/503] Fetching CRWD\n",
      "2025-10-30 10:46:33,575 | INFO | [132/503] Fetching CCI\n",
      "2025-10-30 10:46:35,525 | INFO | [133/503] Fetching CSX\n",
      "2025-10-30 10:46:37,255 | INFO | [134/503] Fetching CMI\n",
      "2025-10-30 10:46:38,924 | INFO | [135/503] Fetching CVS\n",
      "2025-10-30 10:46:40,750 | INFO | [136/503] Fetching DHR\n",
      "2025-10-30 10:46:42,682 | INFO | [137/503] Fetching DRI\n",
      "2025-10-30 10:46:44,415 | INFO | [138/503] Fetching DDOG\n",
      "2025-10-30 10:46:46,110 | INFO | [139/503] Fetching DVA\n",
      "2025-10-30 10:46:47,749 | INFO | [140/503] Fetching DAY\n",
      "2025-10-30 10:46:49,545 | INFO | [141/503] Fetching DECK\n",
      "2025-10-30 10:46:51,394 | INFO | [142/503] Fetching DE\n",
      "2025-10-30 10:46:53,109 | INFO | [143/503] Fetching DELL\n",
      "2025-10-30 10:46:54,781 | INFO | [144/503] Fetching DAL\n",
      "2025-10-30 10:46:56,604 | INFO | [145/503] Fetching DVN\n",
      "2025-10-30 10:46:58,396 | INFO | [146/503] Fetching DXCM\n",
      "2025-10-30 10:47:00,141 | INFO | [147/503] Fetching FANG\n",
      "2025-10-30 10:47:01,938 | INFO | [148/503] Fetching DLR\n",
      "2025-10-30 10:47:03,771 | INFO | [149/503] Fetching DG\n",
      "2025-10-30 10:47:05,563 | INFO | [150/503] Fetching DLTR\n",
      "2025-10-30 10:47:07,355 | INFO | [151/503] Fetching D\n",
      "2025-10-30 10:47:09,111 | INFO | [152/503] Fetching DPZ\n",
      "2025-10-30 10:47:10,805 | INFO | [153/503] Fetching DASH\n",
      "2025-10-30 10:47:12,579 | INFO | [154/503] Fetching DOV\n",
      "2025-10-30 10:47:14,296 | INFO | [155/503] Fetching DOW\n",
      "2025-10-30 10:47:16,107 | INFO | [156/503] Fetching DHI\n",
      "2025-10-30 10:47:17,879 | INFO | [157/503] Fetching DTE\n",
      "2025-10-30 10:47:19,610 | INFO | [158/503] Fetching DUK\n",
      "2025-10-30 10:47:21,325 | INFO | [159/503] Fetching DD\n",
      "2025-10-30 10:47:23,065 | INFO | [160/503] Fetching EMN\n",
      "2025-10-30 10:47:24,790 | INFO | [161/503] Fetching ETN\n",
      "2025-10-30 10:47:26,604 | INFO | [162/503] Fetching EBAY\n",
      "2025-10-30 10:47:28,355 | INFO | [163/503] Fetching ECL\n",
      "2025-10-30 10:47:30,092 | INFO | [164/503] Fetching EIX\n",
      "2025-10-30 10:47:32,163 | INFO | [165/503] Fetching EW\n",
      "2025-10-30 10:47:33,864 | INFO | [166/503] Fetching EA\n",
      "2025-10-30 10:47:35,576 | INFO | [167/503] Fetching ELV\n",
      "2025-10-30 10:47:37,250 | INFO | [168/503] Fetching EMR\n",
      "2025-10-30 10:47:38,967 | INFO | [169/503] Fetching ENPH\n",
      "2025-10-30 10:47:40,687 | INFO | [170/503] Fetching ETR\n",
      "2025-10-30 10:47:42,383 | INFO | [171/503] Fetching EOG\n",
      "2025-10-30 10:47:44,169 | INFO | [172/503] Fetching EPAM\n",
      "2025-10-30 10:47:45,967 | INFO | [173/503] Fetching EQT\n",
      "2025-10-30 10:47:47,701 | INFO | [174/503] Fetching EFX\n",
      "2025-10-30 10:47:49,390 | INFO | [175/503] Fetching EQIX\n",
      "2025-10-30 10:47:51,101 | INFO | [176/503] Fetching EQR\n",
      "2025-10-30 10:47:52,823 | INFO | [177/503] Fetching ERIE\n",
      "2025-10-30 10:47:54,522 | INFO | [178/503] Fetching ESS\n",
      "2025-10-30 10:47:56,313 | INFO | [179/503] Fetching EL\n",
      "2025-10-30 10:47:58,144 | INFO | [180/503] Fetching EG\n",
      "2025-10-30 10:47:59,943 | INFO | [181/503] Fetching EVRG\n",
      "2025-10-30 10:48:01,597 | INFO | [182/503] Fetching ES\n",
      "2025-10-30 10:48:03,377 | INFO | [183/503] Fetching EXC\n",
      "2025-10-30 10:48:05,213 | INFO | [184/503] Fetching EXE\n",
      "2025-10-30 10:48:06,894 | INFO | [185/503] Fetching EXPE\n",
      "2025-10-30 10:48:08,712 | INFO | [186/503] Fetching EXPD\n",
      "2025-10-30 10:48:10,484 | INFO | [187/503] Fetching EXR\n",
      "2025-10-30 10:48:12,181 | INFO | [188/503] Fetching XOM\n",
      "2025-10-30 10:48:14,026 | INFO | [189/503] Fetching FFIV\n",
      "2025-10-30 10:48:15,709 | INFO | [190/503] Fetching FDS\n",
      "2025-10-30 10:48:17,500 | INFO | [191/503] Fetching FICO\n",
      "2025-10-30 10:48:19,244 | INFO | [192/503] Fetching FAST\n",
      "2025-10-30 10:48:20,980 | INFO | [193/503] Fetching FRT\n",
      "2025-10-30 10:48:22,732 | INFO | [194/503] Fetching FDX\n",
      "2025-10-30 10:51:07,557 | INFO | [195/503] Fetching FIS\n",
      "2025-10-30 10:51:07,591 | ERROR | Error FIS: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=FIS&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002204C251450>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 10:51:08,695 | INFO | [196/503] Fetching FITB\n",
      "2025-10-30 10:51:08,698 | ERROR | Error FITB: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=FITB&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2C550>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 10:51:09,800 | INFO | [197/503] Fetching FSLR\n",
      "2025-10-30 10:51:11,686 | INFO | [198/503] Fetching FE\n",
      "2025-10-30 10:51:13,411 | INFO | [199/503] Fetching FI\n",
      "2025-10-30 10:51:15,076 | INFO | [200/503] Fetching F\n",
      "2025-10-30 10:51:16,809 | INFO | [201/503] Fetching FTNT\n",
      "2025-10-30 10:51:18,563 | INFO | [202/503] Fetching FTV\n",
      "2025-10-30 10:51:20,340 | INFO | [203/503] Fetching FOXA\n",
      "2025-10-30 10:51:22,080 | INFO | [204/503] Fetching FOX\n",
      "2025-10-30 10:51:23,797 | INFO | [205/503] Fetching BEN\n",
      "2025-10-30 10:51:25,611 | INFO | [206/503] Fetching FCX\n",
      "2025-10-30 10:51:27,461 | INFO | [207/503] Fetching GRMN\n",
      "2025-10-30 10:51:29,205 | INFO | [208/503] Fetching IT\n",
      "2025-10-30 10:51:30,884 | INFO | [209/503] Fetching GE\n",
      "2025-10-30 10:51:32,683 | INFO | [210/503] Fetching GEHC\n",
      "2025-10-30 10:51:34,417 | INFO | [211/503] Fetching GEV\n",
      "2025-10-30 10:51:36,162 | INFO | [212/503] Fetching GEN\n",
      "2025-10-30 10:51:37,908 | INFO | [213/503] Fetching GNRC\n",
      "2025-10-30 10:51:39,616 | INFO | [214/503] Fetching GD\n",
      "2025-10-30 10:51:41,329 | INFO | [215/503] Fetching GIS\n",
      "2025-10-30 10:55:30,870 | ERROR | Error GIS: ('Connection aborted.', ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 10:55:31,979 | INFO | [216/503] Fetching GM\n",
      "2025-10-30 10:55:33,770 | INFO | [217/503] Fetching GPC\n",
      "2025-10-30 10:55:35,451 | INFO | [218/503] Fetching GILD\n",
      "2025-10-30 10:55:37,164 | INFO | [219/503] Fetching GPN\n",
      "2025-10-30 10:55:38,963 | INFO | [220/503] Fetching GL\n",
      "2025-10-30 10:55:40,659 | INFO | [221/503] Fetching GDDY\n",
      "2025-10-30 10:55:42,367 | INFO | [222/503] Fetching GS\n",
      "2025-10-30 10:55:45,046 | INFO | [223/503] Fetching HAL\n",
      "2025-10-30 10:55:46,711 | INFO | [224/503] Fetching HIG\n",
      "2025-10-30 10:55:48,470 | INFO | [225/503] Fetching HAS\n",
      "2025-10-30 10:55:50,269 | INFO | [226/503] Fetching HCA\n",
      "2025-10-30 10:55:51,973 | INFO | [227/503] Fetching DOC\n",
      "2025-10-30 11:01:57,726 | INFO | [228/503] Fetching HSIC\n",
      "2025-10-30 11:01:57,736 | ERROR | Error HSIC: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=HSIC&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2C2D0>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:01:58,838 | INFO | [229/503] Fetching HSY\n",
      "2025-10-30 11:02:00,900 | INFO | [230/503] Fetching HPE\n",
      "2025-10-30 11:02:02,801 | INFO | [231/503] Fetching HLT\n",
      "2025-10-30 11:02:04,546 | INFO | [232/503] Fetching HOLX\n",
      "2025-10-30 11:02:06,290 | INFO | [233/503] Fetching HD\n",
      "2025-10-30 11:02:08,019 | INFO | [234/503] Fetching HON\n",
      "2025-10-30 11:02:09,933 | INFO | [235/503] Fetching HRL\n",
      "2025-10-30 11:02:11,730 | INFO | [236/503] Fetching HST\n",
      "2025-10-30 11:11:57,015 | ERROR | Error HST: ('Connection aborted.', ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 11:11:58,116 | INFO | [237/503] Fetching HWM\n",
      "2025-10-30 11:12:00,057 | INFO | [238/503] Fetching HPQ\n",
      "2025-10-30 11:12:01,782 | INFO | [239/503] Fetching HUBB\n",
      "2025-10-30 11:12:03,533 | INFO | [240/503] Fetching HUM\n",
      "2025-10-30 11:12:05,377 | INFO | [241/503] Fetching HBAN\n",
      "2025-10-30 11:12:07,233 | INFO | [242/503] Fetching HII\n",
      "2025-10-30 11:12:09,185 | INFO | [243/503] Fetching IBM\n",
      "2025-10-30 11:12:10,930 | INFO | [244/503] Fetching IEX\n",
      "2025-10-30 11:12:12,757 | INFO | [245/503] Fetching IDXX\n",
      "2025-10-30 11:12:14,601 | INFO | [246/503] Fetching ITW\n",
      "2025-10-30 11:12:16,346 | INFO | [247/503] Fetching INCY\n",
      "2025-10-30 11:12:18,206 | INFO | [248/503] Fetching IR\n",
      "2025-10-30 11:12:19,890 | INFO | [249/503] Fetching PODD\n",
      "2025-10-30 11:12:21,589 | INFO | [250/503] Fetching INTC\n",
      "2025-10-30 11:12:23,407 | INFO | [251/503] Fetching ICE\n",
      "2025-10-30 11:17:15,547 | ERROR | Error ICE: ('Connection aborted.', ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 11:17:16,648 | INFO | [252/503] Fetching IFF\n",
      "2025-10-30 11:17:18,436 | INFO | [253/503] Fetching IP\n",
      "2025-10-30 11:17:20,139 | INFO | [254/503] Fetching IPG\n",
      "2025-10-30 11:17:21,870 | INFO | [255/503] Fetching INTU\n",
      "2025-10-30 11:17:23,576 | INFO | [256/503] Fetching ISRG\n",
      "2025-10-30 11:17:25,394 | INFO | [257/503] Fetching IVZ\n",
      "2025-10-30 11:20:40,363 | INFO | [258/503] Fetching INVH\n",
      "2025-10-30 11:20:40,383 | ERROR | Error INVH: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=INVH&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2D810>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:20:41,484 | INFO | [259/503] Fetching IQV\n",
      "2025-10-30 11:20:43,469 | INFO | [260/503] Fetching IRM\n",
      "2025-10-30 11:20:45,176 | INFO | [261/503] Fetching JBHT\n",
      "2025-10-30 11:20:47,104 | INFO | [262/503] Fetching JBL\n",
      "2025-10-30 11:20:49,012 | INFO | [263/503] Fetching JKHY\n",
      "2025-10-30 11:20:50,753 | INFO | [264/503] Fetching J\n",
      "2025-10-30 11:20:52,707 | INFO | [265/503] Fetching JNJ\n",
      "2025-10-30 11:21:04,166 | INFO | [266/503] Fetching JCI\n",
      "2025-10-30 11:21:04,206 | ERROR | Error JCI: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=JCI&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2DBD0>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:21:05,635 | INFO | [267/503] Fetching JPM\n",
      "2025-10-30 11:21:05,638 | ERROR | Error JPM: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=JPM&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2DE50>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:21:06,739 | INFO | [268/503] Fetching K\n",
      "2025-10-30 11:21:06,742 | ERROR | Error K: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=K&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2E210>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:21:07,843 | INFO | [269/503] Fetching KVUE\n",
      "2025-10-30 11:21:07,846 | ERROR | Error KVUE: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=KVUE&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2E5D0>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:21:08,951 | INFO | [270/503] Fetching KDP\n",
      "2025-10-30 11:21:08,954 | ERROR | Error KDP: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=KDP&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002204C251450>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:27:07,056 | INFO | [271/503] Fetching KEY\n",
      "2025-10-30 11:27:07,076 | ERROR | Error KEY: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=KEY&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002204BF07B10>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:27:08,178 | INFO | [272/503] Fetching KEYS\n",
      "2025-10-30 11:27:08,180 | ERROR | Error KEYS: HTTPSConnectionPool(host='finnhub.io', port=443): Max retries exceeded with url: /api/v1/stock/profile2?symbol=KEYS&token=d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000022066A2E490>: Failed to resolve 'finnhub.io' ([Errno 11001] getaddrinfo failed)\"))\n",
      "2025-10-30 11:27:09,281 | INFO | [273/503] Fetching KMB\n",
      "2025-10-30 11:27:11,087 | INFO | [274/503] Fetching KIM\n",
      "2025-10-30 11:27:12,727 | INFO | [275/503] Fetching KMI\n",
      "2025-10-30 11:27:14,683 | INFO | [276/503] Fetching KKR\n",
      "2025-10-30 11:27:16,547 | INFO | [277/503] Fetching KLAC\n",
      "2025-10-30 11:27:18,448 | INFO | [278/503] Fetching KHC\n",
      "2025-10-30 11:27:20,376 | INFO | [279/503] Fetching KR\n",
      "2025-10-30 11:27:22,265 | INFO | [280/503] Fetching LHX\n",
      "2025-10-30 11:27:23,930 | INFO | [281/503] Fetching LH\n",
      "2025-10-30 11:27:25,845 | INFO | [282/503] Fetching LRCX\n",
      "2025-10-30 11:27:27,791 | INFO | [283/503] Fetching LW\n",
      "2025-10-30 11:27:29,682 | INFO | [284/503] Fetching LVS\n",
      "2025-10-30 11:27:31,580 | INFO | [285/503] Fetching LDOS\n",
      "2025-10-30 11:27:33,321 | INFO | [286/503] Fetching LEN\n",
      "2025-10-30 11:27:35,264 | INFO | [287/503] Fetching LII\n",
      "2025-10-30 11:27:37,416 | INFO | [288/503] Fetching LLY\n",
      "2025-10-30 11:27:39,467 | INFO | [289/503] Fetching LIN\n",
      "2025-10-30 11:27:41,341 | INFO | [290/503] Fetching LYV\n",
      "2025-10-30 11:27:43,253 | INFO | [291/503] Fetching LKQ\n",
      "2025-10-30 11:27:44,903 | INFO | [292/503] Fetching LMT\n",
      "2025-10-30 11:27:46,801 | INFO | [293/503] Fetching L\n",
      "2025-10-30 11:27:48,681 | INFO | [294/503] Fetching LOW\n",
      "2025-10-30 11:27:50,422 | INFO | [295/503] Fetching LULU\n",
      "2025-10-30 11:27:52,368 | INFO | [296/503] Fetching LYB\n",
      "2025-10-30 11:27:54,279 | INFO | [297/503] Fetching MTB\n",
      "2025-10-30 11:27:56,260 | INFO | [298/503] Fetching MPC\n",
      "2025-10-30 11:27:58,305 | INFO | [299/503] Fetching MKTX\n",
      "2025-10-30 11:28:00,252 | INFO | [300/503] Fetching MAR\n",
      "2025-10-30 11:28:02,136 | INFO | [301/503] Fetching MMC\n",
      "2025-10-30 11:28:04,049 | INFO | [302/503] Fetching MLM\n",
      "2025-10-30 11:28:05,918 | INFO | [303/503] Fetching MAS\n",
      "2025-10-30 11:28:07,691 | INFO | [304/503] Fetching MA\n",
      "2025-10-30 11:28:09,538 | INFO | [305/503] Fetching MTCH\n",
      "2025-10-30 11:28:11,377 | INFO | [306/503] Fetching MKC\n",
      "2025-10-30 11:28:13,122 | INFO | [307/503] Fetching MCD\n",
      "2025-10-30 11:28:14,956 | INFO | [308/503] Fetching MCK\n",
      "2025-10-30 11:28:17,047 | INFO | [309/503] Fetching MDT\n",
      "2025-10-30 11:28:18,946 | INFO | [310/503] Fetching MRK\n",
      "2025-10-30 11:28:20,694 | INFO | [311/503] Fetching META\n",
      "2025-10-30 11:28:22,439 | INFO | [312/503] Fetching MET\n",
      "2025-10-30 11:28:24,281 | INFO | [313/503] Fetching MTD\n",
      "2025-10-30 11:28:26,127 | INFO | [314/503] Fetching MGM\n",
      "2025-10-30 11:28:27,961 | INFO | [315/503] Fetching MCHP\n",
      "2025-10-30 11:28:29,747 | INFO | [316/503] Fetching MU\n",
      "2025-10-30 11:28:31,474 | INFO | [317/503] Fetching MSFT\n",
      "2025-10-30 11:28:33,228 | INFO | [318/503] Fetching MAA\n",
      "2025-10-30 11:28:34,952 | INFO | [319/503] Fetching MRNA\n",
      "2025-10-30 11:28:36,759 | INFO | [320/503] Fetching MHK\n",
      "2025-10-30 11:28:38,450 | INFO | [321/503] Fetching MOH\n",
      "2025-10-30 11:28:40,130 | INFO | [322/503] Fetching TAP\n",
      "2025-10-30 11:28:41,828 | INFO | [323/503] Fetching MDLZ\n",
      "2025-10-30 11:28:43,589 | INFO | [324/503] Fetching MPWR\n",
      "2025-10-30 11:28:45,362 | INFO | [325/503] Fetching MNST\n",
      "2025-10-30 11:28:47,113 | INFO | [326/503] Fetching MCO\n",
      "2025-10-30 11:28:49,050 | INFO | [327/503] Fetching MS\n",
      "2025-10-30 11:28:50,766 | INFO | [328/503] Fetching MOS\n",
      "2025-10-30 11:28:52,478 | INFO | [329/503] Fetching MSI\n",
      "2025-10-30 11:28:54,120 | INFO | [330/503] Fetching MSCI\n",
      "2025-10-30 11:28:55,858 | INFO | [331/503] Fetching NDAQ\n",
      "2025-10-30 11:28:57,580 | INFO | [332/503] Fetching NTAP\n",
      "2025-10-30 11:28:59,247 | INFO | [333/503] Fetching NFLX\n",
      "2025-10-30 11:29:00,946 | INFO | [334/503] Fetching NEM\n",
      "2025-10-30 11:29:02,728 | INFO | [335/503] Fetching NWSA\n",
      "2025-10-30 11:29:04,520 | INFO | [336/503] Fetching NWS\n",
      "2025-10-30 11:29:06,302 | INFO | [337/503] Fetching NEE\n",
      "2025-10-30 11:29:08,026 | INFO | [338/503] Fetching NKE\n",
      "2025-10-30 11:29:09,835 | INFO | [339/503] Fetching NI\n",
      "2025-10-30 11:29:11,626 | INFO | [340/503] Fetching NDSN\n",
      "2025-10-30 11:29:13,352 | INFO | [341/503] Fetching NSC\n",
      "2025-10-30 11:29:15,281 | INFO | [342/503] Fetching NTRS\n",
      "2025-10-30 11:29:17,032 | INFO | [343/503] Fetching NOC\n",
      "2025-10-30 11:29:18,954 | INFO | [344/503] Fetching NCLH\n",
      "2025-10-30 11:29:20,654 | INFO | [345/503] Fetching NRG\n",
      "2025-10-30 11:29:22,530 | INFO | [346/503] Fetching NUE\n",
      "2025-10-30 11:29:24,353 | INFO | [347/503] Fetching NVDA\n",
      "2025-10-30 11:29:26,238 | INFO | [348/503] Fetching NVR\n",
      "2025-10-30 11:29:28,016 | INFO | [349/503] Fetching NXPI\n",
      "2025-10-30 11:29:29,820 | INFO | [350/503] Fetching ORLY\n",
      "2025-10-30 11:29:31,619 | INFO | [351/503] Fetching OXY\n",
      "2025-10-30 11:29:33,396 | INFO | [352/503] Fetching ODFL\n",
      "2025-10-30 11:29:36,255 | INFO | [353/503] Fetching OMC\n",
      "2025-10-30 11:29:38,026 | INFO | [354/503] Fetching ON\n",
      "2025-10-30 11:29:39,746 | INFO | [355/503] Fetching OKE\n",
      "2025-10-30 11:29:41,506 | INFO | [356/503] Fetching ORCL\n",
      "2025-10-30 11:29:43,322 | INFO | [357/503] Fetching OTIS\n",
      "2025-10-30 11:29:44,993 | INFO | [358/503] Fetching PCAR\n",
      "2025-10-30 11:29:46,752 | INFO | [359/503] Fetching PKG\n",
      "2025-10-30 11:29:48,654 | INFO | [360/503] Fetching PLTR\n",
      "2025-10-30 11:29:50,490 | INFO | [361/503] Fetching PANW\n",
      "2025-10-30 11:29:52,350 | INFO | [362/503] Fetching PSKY\n",
      "2025-10-30 11:29:54,149 | INFO | [363/503] Fetching PH\n",
      "2025-10-30 11:29:55,967 | INFO | [364/503] Fetching PAYX\n",
      "2025-10-30 11:29:57,727 | INFO | [365/503] Fetching PAYC\n",
      "2025-10-30 11:29:59,511 | INFO | [366/503] Fetching PYPL\n",
      "2025-10-30 11:30:01,248 | INFO | [367/503] Fetching PNR\n",
      "2025-10-30 11:30:03,089 | INFO | [368/503] Fetching PEP\n",
      "2025-10-30 11:30:04,951 | INFO | [369/503] Fetching PFE\n",
      "2025-10-30 11:30:06,770 | INFO | [370/503] Fetching PCG\n",
      "2025-10-30 11:30:08,451 | INFO | [371/503] Fetching PM\n",
      "2025-10-30 11:30:10,218 | INFO | [372/503] Fetching PSX\n",
      "2025-10-30 11:30:12,003 | INFO | [373/503] Fetching PNW\n",
      "2025-10-30 11:30:13,708 | INFO | [374/503] Fetching PNC\n",
      "2025-10-30 11:30:15,506 | INFO | [375/503] Fetching POOL\n",
      "2025-10-30 11:30:17,337 | INFO | [376/503] Fetching PPG\n",
      "2025-10-30 11:30:19,209 | INFO | [377/503] Fetching PPL\n",
      "2025-10-30 11:30:20,955 | INFO | [378/503] Fetching PFG\n",
      "2025-10-30 11:30:22,750 | INFO | [379/503] Fetching PG\n",
      "2025-10-30 11:30:24,604 | INFO | [380/503] Fetching PGR\n",
      "2025-10-30 11:30:26,375 | INFO | [381/503] Fetching PLD\n",
      "2025-10-30 11:30:30,993 | INFO | [382/503] Fetching PRU\n",
      "2025-10-30 11:30:33,390 | INFO | [383/503] Fetching PEG\n",
      "2025-10-30 11:30:35,331 | INFO | [384/503] Fetching PTC\n",
      "2025-10-30 11:30:42,606 | ERROR | Error PTC: ('Connection aborted.', ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 11:30:43,708 | INFO | [385/503] Fetching PSA\n",
      "2025-10-30 11:30:45,531 | INFO | [386/503] Fetching PHM\n",
      "2025-10-30 11:30:47,454 | INFO | [387/503] Fetching PWR\n",
      "2025-10-30 11:30:49,276 | INFO | [388/503] Fetching QCOM\n",
      "2025-10-30 11:30:51,195 | INFO | [389/503] Fetching DGX\n",
      "2025-10-30 11:30:53,068 | INFO | [390/503] Fetching RL\n",
      "2025-10-30 11:30:54,958 | INFO | [391/503] Fetching RJF\n",
      "2025-10-30 11:30:56,799 | INFO | [392/503] Fetching RTX\n",
      "2025-10-30 11:30:58,653 | INFO | [393/503] Fetching O\n",
      "2025-10-30 11:31:00,388 | INFO | [394/503] Fetching REG\n",
      "2025-10-30 11:31:02,087 | INFO | [395/503] Fetching REGN\n",
      "2025-10-30 11:31:03,887 | INFO | [396/503] Fetching RF\n",
      "2025-10-30 11:31:05,617 | INFO | [397/503] Fetching RSG\n",
      "2025-10-30 11:31:07,321 | INFO | [398/503] Fetching RMD\n",
      "2025-10-30 11:31:09,019 | INFO | [399/503] Fetching RVTY\n",
      "2025-10-30 11:31:10,784 | INFO | [400/503] Fetching ROK\n",
      "2025-10-30 11:31:12,512 | INFO | [401/503] Fetching ROL\n",
      "2025-10-30 11:31:14,325 | INFO | [402/503] Fetching ROP\n",
      "2025-10-30 11:31:16,178 | INFO | [403/503] Fetching ROST\n",
      "2025-10-30 11:31:17,871 | INFO | [404/503] Fetching RCL\n",
      "2025-10-30 11:31:19,683 | INFO | [405/503] Fetching SPGI\n",
      "2025-10-30 11:31:21,348 | INFO | [406/503] Fetching CRM\n",
      "2025-10-30 11:31:23,119 | INFO | [407/503] Fetching SBAC\n",
      "2025-10-30 11:31:24,818 | INFO | [408/503] Fetching SLB\n",
      "2025-10-30 11:31:26,614 | INFO | [409/503] Fetching STX\n",
      "2025-10-30 11:31:28,360 | INFO | [410/503] Fetching SRE\n",
      "2025-10-30 11:31:30,208 | INFO | [411/503] Fetching NOW\n",
      "2025-10-30 11:31:31,983 | INFO | [412/503] Fetching SHW\n",
      "2025-10-30 11:31:33,730 | INFO | [413/503] Fetching SPG\n",
      "2025-10-30 11:31:35,471 | INFO | [414/503] Fetching SWKS\n",
      "2025-10-30 11:31:37,197 | INFO | [415/503] Fetching SJM\n",
      "2025-10-30 11:31:38,999 | INFO | [416/503] Fetching SW\n",
      "2025-10-30 11:31:40,752 | INFO | [417/503] Fetching SNA\n",
      "2025-10-30 11:31:42,460 | INFO | [418/503] Fetching SOLV\n",
      "2025-10-30 11:31:44,182 | INFO | [419/503] Fetching SO\n",
      "2025-10-30 11:31:45,910 | INFO | [420/503] Fetching LUV\n",
      "2025-10-30 11:31:47,598 | INFO | [421/503] Fetching SWK\n",
      "2025-10-30 11:31:49,397 | INFO | [422/503] Fetching SBUX\n",
      "2025-10-30 11:31:51,183 | INFO | [423/503] Fetching STT\n",
      "2025-10-30 11:31:52,943 | INFO | [424/503] Fetching STLD\n",
      "2025-10-30 11:31:54,791 | INFO | [425/503] Fetching STE\n",
      "2025-10-30 11:31:56,516 | INFO | [426/503] Fetching SYK\n",
      "2025-10-30 11:31:58,368 | INFO | [427/503] Fetching SMCI\n",
      "2025-10-30 11:32:00,202 | INFO | [428/503] Fetching SYF\n",
      "2025-10-30 11:32:02,055 | INFO | [429/503] Fetching SNPS\n",
      "2025-10-30 11:32:03,818 | INFO | [430/503] Fetching SYY\n",
      "2025-10-30 11:32:05,622 | INFO | [431/503] Fetching TMUS\n",
      "2025-10-30 11:32:07,476 | INFO | [432/503] Fetching TROW\n",
      "2025-10-30 11:32:09,265 | INFO | [433/503] Fetching TTWO\n",
      "2025-10-30 11:32:10,990 | INFO | [434/503] Fetching TPR\n",
      "2025-10-30 11:32:12,733 | INFO | [435/503] Fetching TRGP\n",
      "2025-10-30 11:32:14,547 | INFO | [436/503] Fetching TGT\n",
      "2025-10-30 11:32:16,361 | INFO | [437/503] Fetching TEL\n",
      "2025-10-30 11:32:18,243 | INFO | [438/503] Fetching TDY\n",
      "2025-10-30 11:32:19,984 | INFO | [439/503] Fetching TER\n",
      "2025-10-30 11:32:21,811 | INFO | [440/503] Fetching TSLA\n",
      "2025-10-30 11:32:23,553 | INFO | [441/503] Fetching TXN\n",
      "2025-10-30 11:32:25,341 | INFO | [442/503] Fetching TPL\n",
      "2025-10-30 11:32:27,127 | INFO | [443/503] Fetching TXT\n",
      "2025-10-30 11:32:28,973 | INFO | [444/503] Fetching TMO\n",
      "2025-10-30 11:32:30,692 | INFO | [445/503] Fetching TJX\n",
      "2025-10-30 11:32:32,471 | INFO | [446/503] Fetching TKO\n",
      "2025-10-30 11:32:34,112 | INFO | [447/503] Fetching TTD\n",
      "2025-10-30 11:32:35,885 | INFO | [448/503] Fetching TSCO\n",
      "2025-10-30 11:32:37,625 | INFO | [449/503] Fetching TT\n",
      "2025-10-30 11:32:39,436 | INFO | [450/503] Fetching TDG\n",
      "2025-10-30 11:32:41,135 | INFO | [451/503] Fetching TRV\n",
      "2025-10-30 11:32:42,910 | INFO | [452/503] Fetching TRMB\n",
      "2025-10-30 11:32:44,760 | INFO | [453/503] Fetching TFC\n",
      "2025-10-30 11:32:46,495 | INFO | [454/503] Fetching TYL\n",
      "2025-10-30 11:32:48,231 | INFO | [455/503] Fetching TSN\n",
      "2025-10-30 11:32:50,050 | INFO | [456/503] Fetching USB\n",
      "2025-10-30 11:32:51,812 | INFO | [457/503] Fetching UBER\n",
      "2025-10-30 11:32:53,533 | INFO | [458/503] Fetching UDR\n",
      "2025-10-30 11:32:55,305 | INFO | [459/503] Fetching ULTA\n",
      "2025-10-30 11:32:57,150 | INFO | [460/503] Fetching UNP\n",
      "2025-10-30 11:32:58,926 | INFO | [461/503] Fetching UAL\n",
      "2025-10-30 11:33:00,665 | INFO | [462/503] Fetching UPS\n",
      "2025-10-30 11:33:02,392 | INFO | [463/503] Fetching URI\n",
      "2025-10-30 11:33:04,214 | INFO | [464/503] Fetching UNH\n",
      "2025-10-30 11:33:05,997 | INFO | [465/503] Fetching UHS\n",
      "2025-10-30 11:33:07,705 | INFO | [466/503] Fetching VLO\n",
      "2025-10-30 11:33:09,525 | INFO | [467/503] Fetching VTR\n",
      "2025-10-30 11:33:11,233 | INFO | [468/503] Fetching VLTO\n",
      "2025-10-30 11:33:12,958 | INFO | [469/503] Fetching VRSN\n",
      "2025-10-30 11:33:14,691 | INFO | [470/503] Fetching VRSK\n",
      "2025-10-30 11:33:16,409 | INFO | [471/503] Fetching VZ\n",
      "2025-10-30 11:33:18,057 | INFO | [472/503] Fetching VRTX\n",
      "2025-10-30 11:33:19,865 | INFO | [473/503] Fetching VTRS\n",
      "2025-10-30 11:33:31,556 | ERROR | Error VTRS: (\"Connection broken: ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None)\", ConnectionResetError(10054, '遠端主機已強制關閉一個現存的連線。', None, 10054, None))\n",
      "2025-10-30 11:33:32,657 | INFO | [474/503] Fetching VICI\n",
      "2025-10-30 11:33:34,512 | INFO | [475/503] Fetching V\n",
      "2025-10-30 11:33:36,247 | INFO | [476/503] Fetching VST\n",
      "2025-10-30 11:33:38,105 | INFO | [477/503] Fetching VMC\n",
      "2025-10-30 11:33:39,936 | INFO | [478/503] Fetching WRB\n",
      "2025-10-30 11:33:41,793 | INFO | [479/503] Fetching GWW\n",
      "2025-10-30 11:33:43,510 | INFO | [480/503] Fetching WAB\n",
      "2025-10-30 11:33:45,267 | INFO | [481/503] Fetching WBA\n",
      "2025-10-30 11:33:47,005 | INFO | [482/503] Fetching WMT\n",
      "2025-10-30 11:33:48,743 | INFO | [483/503] Fetching DIS\n",
      "2025-10-30 11:33:50,596 | INFO | [484/503] Fetching WBD\n",
      "2025-10-30 11:33:52,325 | INFO | [485/503] Fetching WM\n",
      "2025-10-30 11:33:54,118 | INFO | [486/503] Fetching WAT\n",
      "2025-10-30 11:33:55,911 | INFO | [487/503] Fetching WEC\n",
      "2025-10-30 11:33:57,761 | INFO | [488/503] Fetching WFC\n",
      "2025-10-30 11:33:59,597 | INFO | [489/503] Fetching WELL\n",
      "2025-10-30 11:34:01,360 | INFO | [490/503] Fetching WST\n",
      "2025-10-30 11:34:03,258 | INFO | [491/503] Fetching WDC\n",
      "2025-10-30 11:34:05,077 | INFO | [492/503] Fetching WY\n",
      "2025-10-30 11:34:06,874 | INFO | [493/503] Fetching WSM\n",
      "2025-10-30 11:34:08,611 | INFO | [494/503] Fetching WMB\n",
      "2025-10-30 11:34:10,314 | INFO | [495/503] Fetching WTW\n",
      "2025-10-30 11:34:12,096 | INFO | [496/503] Fetching WDAY\n",
      "2025-10-30 11:34:13,839 | INFO | [497/503] Fetching WYNN\n",
      "2025-10-30 11:34:15,586 | INFO | [498/503] Fetching XEL\n",
      "2025-10-30 11:34:17,417 | INFO | [499/503] Fetching XYL\n",
      "2025-10-30 11:34:19,166 | INFO | [500/503] Fetching YUM\n",
      "2025-10-30 11:34:20,876 | INFO | [501/503] Fetching ZBRA\n",
      "2025-10-30 11:34:22,596 | INFO | [502/503] Fetching ZBH\n",
      "2025-10-30 11:34:24,331 | INFO | [503/503] Fetching ZTS\n",
      "2025-10-30 11:34:26,229 | INFO | SUCCESS: All 503 profiles saved to:\n",
      "   C:\\github\\Bootcamp-Final-Project\\python\\sp500_finnhub_profiles.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "save_all_finnhub_to_one_json.py\n",
    "-------------------------------\n",
    "Read sp500_symbols.txt → fetch Finnhub profile2 → save ALL to ONE JSON file\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------------------\n",
    "FINNHUB_TOKEN = \"d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg\"\n",
    "FINNHUB_URL   = \"https://finnhub.io/api/v1/stock/profile2\"\n",
    "\n",
    "SYMBOLS_TXT   = \"sp500_symbols.txt\"\n",
    "\n",
    "# OUTPUT PATH (Windows style)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_PATH = Path(f\"C:/github/Bootcamp-Final-Project/python/sp500_finnhub_profiles_{timestamp}.json\")\n",
    "\n",
    "REQUEST_DELAY = 1.1  # Safe for free tier\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Logging\n",
    "# ----------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"fetch_one_json.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def load_symbols() -> List[str]:\n",
    "    p = Path(SYMBOLS_TXT)\n",
    "    if not p.is_file():\n",
    "        log.error(f\"{SYMBOLS_TXT} not found in current directory!\")\n",
    "        return []\n",
    "    syms = [ln.strip().upper() for ln in p.open() if ln.strip() and not ln.startswith(\"#\")]\n",
    "    log.info(f\"Loaded {len(syms)} symbols\")\n",
    "    return syms\n",
    "\n",
    "def finnhub_profile(symbol: str) -> Dict[str, Any]:\n",
    "    sym = symbol.replace(\".\", \"-\")\n",
    "    url = f\"{FINNHUB_URL}?symbol={sym}&token={FINNHUB_TOKEN}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=12)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data if isinstance(data, dict) else {}\n",
    "        if r.status_code == 429:\n",
    "            log.warning(f\"Rate limit – sleep 15s for {symbol}\")\n",
    "            time.sleep(15)\n",
    "            return finnhub_profile(symbol)\n",
    "        log.warning(f\"HTTP {r.status_code} for {symbol}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error {symbol}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Main\n",
    "# ----------------------------------------------------------------------\n",
    "def main() -> None:\n",
    "    symbols = load_symbols()\n",
    "    if not symbols:\n",
    "        return\n",
    "\n",
    "    # Ensure parent directory exists\n",
    "    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    log.info(f\"Starting fetch → saving to {OUTPUT_PATH}\")\n",
    "\n",
    "    for i, sym in enumerate(symbols, 1):\n",
    "        log.info(f\"[{i}/{len(symbols)}] Fetching {sym}\")\n",
    "        profile = finnhub_profile(sym)\n",
    "        all_data[sym] = profile\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    # Save all at once\n",
    "    try:\n",
    "        with OUTPUT_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "        log.info(f\"SUCCESS: All {len(all_data)} profiles saved to:\\n   {OUTPUT_PATH}\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"Failed to write file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a86104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:19:16,014 | INFO | Loading from: C:\\github\\Bootcamp-Final-Project\\python\\sp500_finnhub_profiles.json\n",
      "2025-10-30 12:19:16,022 | INFO | Loaded 503 profiles\n",
      "2025-10-30 12:19:16,126 | INFO | Table sp500_finnhub_profile created with clear unit column names\n",
      "2025-10-30 12:19:16,178 | INFO | Committed 50 rows\n",
      "2025-10-30 12:19:16,217 | WARNING | Skipping empty: COR\n",
      "2025-10-30 12:19:16,226 | INFO | Committed 100 rows\n",
      "2025-10-30 12:19:16,246 | WARNING | Skipping empty: CEG\n",
      "2025-10-30 12:19:16,247 | WARNING | Skipping empty: COO\n",
      "2025-10-30 12:19:16,248 | WARNING | Skipping empty: CPRT\n",
      "2025-10-30 12:19:16,277 | INFO | Committed 150 rows\n",
      "2025-10-30 12:19:16,313 | WARNING | Skipping empty: FIS\n",
      "2025-10-30 12:19:16,315 | WARNING | Skipping empty: FITB\n",
      "2025-10-30 12:19:16,326 | INFO | Committed 200 rows\n",
      "2025-10-30 12:19:16,335 | WARNING | Skipping empty: GIS\n",
      "2025-10-30 12:19:16,348 | WARNING | Skipping empty: HSIC\n",
      "2025-10-30 12:19:16,355 | WARNING | Skipping empty: HST\n",
      "2025-10-30 12:19:16,368 | WARNING | Skipping empty: ICE\n",
      "2025-10-30 12:19:16,374 | WARNING | Skipping empty: INVH\n",
      "2025-10-30 12:19:16,380 | INFO | Committed 250 rows\n",
      "2025-10-30 12:19:16,385 | WARNING | Skipping empty: JCI\n",
      "2025-10-30 12:19:16,386 | WARNING | Skipping empty: JPM\n",
      "2025-10-30 12:19:16,387 | WARNING | Skipping empty: K\n",
      "2025-10-30 12:19:16,389 | WARNING | Skipping empty: KVUE\n",
      "2025-10-30 12:19:16,389 | WARNING | Skipping empty: KDP\n",
      "2025-10-30 12:19:16,391 | WARNING | Skipping empty: KEY\n",
      "2025-10-30 12:19:16,392 | WARNING | Skipping empty: KEYS\n",
      "2025-10-30 12:19:16,429 | INFO | Committed 300 rows\n",
      "2025-10-30 12:19:16,472 | INFO | Committed 350 rows\n",
      "2025-10-30 12:19:16,484 | WARNING | Skipping empty: PTC\n",
      "2025-10-30 12:19:16,513 | INFO | Committed 400 rows\n",
      "2025-10-30 12:19:16,559 | INFO | Committed 450 rows\n",
      "2025-10-30 12:19:16,564 | WARNING | Skipping empty: VTRS\n",
      "2025-10-30 12:19:16,592 | INFO | SUCCESS: 483 records loaded with clear column names\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "load_json_to_postgres_clarity.py\n",
    "-------------------------------\n",
    "Load sp500_finnhub_profiles_*.json → PostgreSQL\n",
    "Keep original numbers, just rename columns to show units\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------------------\n",
    "JSON_GLOB = \"C:/github/Bootcamp-Final-Project/python/sp500_finnhub_profiles.json\"\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"bootcamp_2508_final_project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"admin1234\"\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Logging\n",
    "# ----------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"load_json_clarity.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Create table with CLEAR column names\n",
    "# ----------------------------------------------------------------------\n",
    "def ensure_table(cur) -> None:\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sp500_finnhub_profiles (\n",
    "        symbol                     VARCHAR(10) PRIMARY KEY,\n",
    "        country                    VARCHAR(100),\n",
    "        currency                   VARCHAR(10),\n",
    "        estimate_currency          VARCHAR(10),\n",
    "        exchange                   VARCHAR(255),\n",
    "        main_industry              VARCHAR(255),\n",
    "\n",
    "        -- === UNITS CLEARLY STATED IN COLUMN NAME ===\n",
    "        floating_share_millions    NUMERIC,   -- in millions (e.g., 14547.72 = 14.5B shares)\n",
    "        market_cap_usd_millions    NUMERIC,   -- in USD millions (e.g., 4002453 = $4T)\n",
    "        share_outstanding_millions NUMERIC,   -- in millions\n",
    "\n",
    "        ipo_date                   DATE,\n",
    "        logo                       TEXT,\n",
    "        name                       VARCHAR(255),\n",
    "        phone                      VARCHAR(50),\n",
    "        ticker                     VARCHAR(10),\n",
    "        weburl                     TEXT,\n",
    "        raw_json                   JSONB      -- full original Finnhub response\n",
    "    );\n",
    "    \"\"\")\n",
    "    log.info(\"Table sp500_finnhub_profile created with clear unit column names\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Upsert: map Finnhub fields → renamed columns (NO SCALING!)\n",
    "# ----------------------------------------------------------------------\n",
    "def upsert(cur, symbol: str, data: Dict[str, Any]) -> None:\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO sp500_finnhub_profiles (\n",
    "        symbol, country, currency, estimate_currency, exchange,\n",
    "        main_industry,\n",
    "        floating_share_millions, market_cap_usd_millions, share_outstanding_millions,\n",
    "        ipo_date, logo, name, phone, ticker, weburl, raw_json\n",
    "    ) VALUES (\n",
    "        %(symbol)s, %(country)s, %(currency)s, %(estimateCurrency)s,\n",
    "        %(exchange)s, %(finnhubIndustry)s,\n",
    "        %(floatingShare)s, %(marketCapitalization)s, %(shareOutstanding)s,\n",
    "        %(ipo)s::date, %(logo)s, %(name)s, %(phone)s,\n",
    "        %(ticker)s, %(weburl)s, %(raw_json)s\n",
    "    )\n",
    "    ON CONFLICT (symbol) DO UPDATE SET\n",
    "        country                    = EXCLUDED.country,\n",
    "        currency                   = EXCLUDED.currency,\n",
    "        estimate_currency          = EXCLUDED.estimate_currency,\n",
    "        exchange                   = EXCLUDED.exchange,\n",
    "        main_industry              = EXCLUDED.main_industry,\n",
    "        floating_share_millions    = EXCLUDED.floating_share_millions,\n",
    "        market_cap_usd_millions    = EXCLUDED.market_cap_usd_millions,\n",
    "        share_outstanding_millions = EXCLUDED.share_outstanding_millions,\n",
    "        ipo_date                   = EXCLUDED.ipo_date,\n",
    "        logo                       = EXCLUDED.logo,\n",
    "        name                       = EXCLUDED.name,\n",
    "        phone                      = EXCLUDED.phone,\n",
    "        ticker                     = EXCLUDED.ticker,\n",
    "        weburl                     = EXCLUDED.weburl,\n",
    "        raw_json                   = EXCLUDED.raw_json;\n",
    "    \"\"\", {\n",
    "        \"symbol\": symbol,\n",
    "        \"country\": data.get(\"country\"),\n",
    "        \"currency\": data.get(\"currency\"),\n",
    "        \"estimateCurrency\": data.get(\"estimateCurrency\"),\n",
    "        \"exchange\": data.get(\"exchange\"),\n",
    "        \"finnhubIndustry\": data.get(\"finnhubIndustry\"),\n",
    "\n",
    "        # Direct mapping — NO division!\n",
    "        \"floatingShare\": data.get(\"floatingShare\"),\n",
    "        \"marketCapitalization\": data.get(\"marketCapitalization\"),\n",
    "        \"shareOutstanding\": data.get(\"shareOutstanding\"),\n",
    "\n",
    "        \"ipo\": data.get(\"ipo\"),\n",
    "        \"logo\": data.get(\"logo\"),\n",
    "        \"name\": data.get(\"name\"),\n",
    "        \"phone\": data.get(\"phone\"),\n",
    "        \"ticker\": data.get(\"ticker\"),\n",
    "        \"weburl\": data.get(\"weburl\"),\n",
    "        \"raw_json\": psycopg2.extras.Json(data)\n",
    "    })\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Main\n",
    "# ----------------------------------------------------------------------\n",
    "def main() -> None:\n",
    "    json_files = list(Path(\"C:/github/Bootcamp-Final-Project/python\").glob(\"sp500_finnhub_profiles.json\"))\n",
    "    if not json_files:\n",
    "        log.error(\"No JSON file found!\")\n",
    "        return\n",
    "    json_path = max(json_files, key=lambda p: p.stat().st_mtime)\n",
    "    log.info(f\"Loading from: {json_path}\")\n",
    "\n",
    "    try:\n",
    "        with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            all_data = json.load(f)\n",
    "        log.info(f\"Loaded {len(all_data)} profiles\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"JSON read error: {e}\")\n",
    "        return\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        ensure_table(cur)\n",
    "\n",
    "        count = 0\n",
    "        for symbol, profile in all_data.items():\n",
    "            if not profile:\n",
    "                log.warning(f\"Skipping empty: {symbol}\")\n",
    "                continue\n",
    "            upsert(cur, symbol, profile)\n",
    "            count += 1\n",
    "            if count % 50 == 0:\n",
    "                conn.commit()\n",
    "                log.info(f\"Committed {count} rows\")\n",
    "\n",
    "        conn.commit()\n",
    "        log.info(f\"SUCCESS: {count} records loaded with clear column names\")\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        log.error(f\"DB error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cc7161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:33:05,276 | INFO | Loaded 503 profiles from C:\\github\\Bootcamp-Final-Project\\python\\sp500_finnhub_profiles.json\n",
      "2025-10-30 12:33:05,278 | INFO | Found 20 failures: ['COR', 'CEG', 'COO', 'CPRT', 'FIS', 'FITB', 'GIS', 'HSIC', 'HST', 'ICE', 'INVH', 'JCI', 'JPM', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'PTC', 'VTRS']\n",
      "2025-10-30 12:33:05,280 | INFO | Saved failures to failed_finnhub_profiles.txt\n",
      "2025-10-30 12:33:05,282 | INFO | Refetching COR\n",
      "2025-10-30 12:33:06,487 | INFO | Success: COR → Cencora Inc\n",
      "2025-10-30 12:33:07,589 | INFO | Refetching CEG\n",
      "2025-10-30 12:33:08,540 | INFO | Success: CEG → Constellation Energy Corp\n",
      "2025-10-30 12:33:09,642 | INFO | Refetching COO\n",
      "2025-10-30 12:33:10,586 | INFO | Success: COO → Cooper Companies Inc\n",
      "2025-10-30 12:33:11,688 | INFO | Refetching CPRT\n",
      "2025-10-30 12:33:12,626 | INFO | Success: CPRT → Copart Inc\n",
      "2025-10-30 12:33:13,729 | INFO | Refetching FIS\n",
      "2025-10-30 12:33:14,646 | INFO | Success: FIS → Fidelity National Information Services Inc\n",
      "2025-10-30 12:33:15,748 | INFO | Refetching FITB\n",
      "2025-10-30 12:33:16,583 | INFO | Success: FITB → Fifth Third Bancorp\n",
      "2025-10-30 12:33:17,686 | INFO | Refetching GIS\n",
      "2025-10-30 12:33:18,569 | INFO | Success: GIS → General Mills Inc\n",
      "2025-10-30 12:33:19,671 | INFO | Refetching HSIC\n",
      "2025-10-30 12:33:20,978 | INFO | Success: HSIC → Henry Schein Inc\n",
      "2025-10-30 12:33:22,081 | INFO | Refetching HST\n",
      "2025-10-30 12:33:22,971 | INFO | Success: HST → Host Hotels & Resorts Inc\n",
      "2025-10-30 12:33:24,073 | INFO | Refetching ICE\n",
      "2025-10-30 12:33:25,023 | INFO | Success: ICE → Intercontinental Exchange Inc\n",
      "2025-10-30 12:33:26,126 | INFO | Refetching INVH\n",
      "2025-10-30 12:33:27,083 | INFO | Success: INVH → Invitation Homes Inc\n",
      "2025-10-30 12:33:28,185 | INFO | Refetching JCI\n",
      "2025-10-30 12:33:29,054 | INFO | Success: JCI → Johnson Controls International PLC\n",
      "2025-10-30 12:33:30,157 | INFO | Refetching JPM\n",
      "2025-10-30 12:33:31,072 | INFO | Success: JPM → JPMorgan Chase & Co\n",
      "2025-10-30 12:33:32,174 | INFO | Refetching K\n",
      "2025-10-30 12:33:33,213 | INFO | Success: K → Kellanova\n",
      "2025-10-30 12:33:34,314 | INFO | Refetching KVUE\n",
      "2025-10-30 12:33:35,236 | INFO | Success: KVUE → Kenvue Inc\n",
      "2025-10-30 12:33:36,338 | INFO | Refetching KDP\n",
      "2025-10-30 12:33:37,257 | INFO | Success: KDP → Keurig Dr Pepper Inc\n",
      "2025-10-30 12:33:38,360 | INFO | Refetching KEY\n",
      "2025-10-30 12:33:39,204 | INFO | Success: KEY → KeyCorp\n",
      "2025-10-30 12:33:40,306 | INFO | Refetching KEYS\n",
      "2025-10-30 12:33:41,102 | INFO | Success: KEYS → Keysight Technologies Inc\n",
      "2025-10-30 12:33:42,204 | INFO | Refetching PTC\n",
      "2025-10-30 12:33:43,083 | INFO | Success: PTC → PTC Inc\n",
      "2025-10-30 12:33:44,185 | INFO | Refetching VTRS\n",
      "2025-10-30 12:33:44,996 | INFO | Success: VTRS → Viatris Inc\n",
      "2025-10-30 12:33:46,115 | INFO | Updated JSON with 20 new profiles\n",
      "2025-10-30 12:33:46,620 | INFO | Re-loaded all data to PostgreSQL\n",
      "2025-10-30 12:33:46,621 | INFO | Refetch complete! Check failed_symbols.txt for any remaining issues.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "refetch_failed_symbols.py\n",
    "-------------------------\n",
    "1. Scan JSON for empty/missing data\n",
    "2. Refetch only failed symbols from Finnhub\n",
    "3. Merge back to original JSON\n",
    "4. (Optional) Re-load to PostgreSQL\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import requests\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ----------------------------------------------------------------------\n",
    "FINNHUB_TOKEN = \"d3rfce1r01qopgh8ajv0d3rfce1r01qopgh8ajvg\"  # Your API key\n",
    "FINNHUB_URL = \"https://finnhub.io/api/v1/stock/profile2\"\n",
    "\n",
    "JSON_GLOB = \"C:/github/Bootcamp-Final-Project/python/sp500_finnhub_profiles.json\"  # Your JSON pattern\n",
    "FAILED_TXT = \"failed_finnhub_profiles.txt\"  # Output: list of symbols to refetch\n",
    "\n",
    "REQUEST_DELAY = 1.1  # Safe rate limit\n",
    "UPDATE_JSON = True   # Set False to skip JSON update\n",
    "RELOAD_DB = True     # Set False to skip DB reload\n",
    "\n",
    "DB_CONFIG = {  # PostgreSQL (if reloading)\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"bootcamp_2508_final_project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"admin1234\"\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Logging\n",
    "# ----------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"refetch_failed.log\"), logging.StreamHandler()]\n",
    ")\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ----------------------------------------------------------------------\n",
    "def load_json() -> tuple[Dict[str, Any], Path]:\n",
    "    \"\"\"Load the latest JSON file.\"\"\"\n",
    "    json_files = list(Path(\"C://github/Bootcamp-Final-Project/python\").glob(\"sp500_finnhub_profiles.json\"))\n",
    "    if not json_files:\n",
    "        log.error(\"No JSON file found!\")\n",
    "        return {}, Path()\n",
    "    json_path = max(json_files, key=lambda p: p.stat().st_mtime)\n",
    "    with json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    log.info(f\"Loaded {len(data)} profiles from {json_path}\")\n",
    "    return data, json_path\n",
    "\n",
    "def find_failures(data: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Find symbols with empty or incomplete profiles.\"\"\"\n",
    "    failures = []\n",
    "    for sym, prof in data.items():\n",
    "        if (not prof or                     # Empty dict\n",
    "            not prof.get(\"name\") or         # No name\n",
    "            \"marketCapitalization\" not in prof or  # No market cap\n",
    "            not prof.get(\"country\")):       # No country\n",
    "            failures.append(sym)\n",
    "    log.info(f\"Found {len(failures)} failures: {failures}\")\n",
    "    return failures\n",
    "\n",
    "def save_failed_list(failures: List[str]) -> None:\n",
    "    \"\"\"Save failures to TXT for manual use.\"\"\"\n",
    "    with open(FAILED_TXT, \"w\") as f:\n",
    "        f.write(\"\\n\".join(failures))\n",
    "    log.info(f\"Saved failures to {FAILED_TXT}\")\n",
    "\n",
    "def finnhub_profile(symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch one profile (with retry).\"\"\"\n",
    "    sym = symbol.replace(\".\", \"-\")\n",
    "    url = f\"{FINNHUB_URL}?symbol={sym}&token={FINNHUB_TOKEN}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=12)\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return data if isinstance(data, dict) else {}\n",
    "        if r.status_code == 429:\n",
    "            log.warning(f\"Rate limit for {symbol} – sleep 15s\")\n",
    "            time.sleep(15)\n",
    "            return finnhub_profile(symbol)\n",
    "        log.warning(f\"HTTP {r.status_code} for {symbol}\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error {symbol}: {e}\")\n",
    "        return {}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Update JSON\n",
    "# ----------------------------------------------------------------------\n",
    "def update_json(data: Dict[str, Any], json_path: Path, new_profiles: Dict[str, Any]) -> None:\n",
    "    \"\"\"Merge new data into original JSON.\"\"\"\n",
    "    for sym, prof in new_profiles.items():\n",
    "        data[sym] = prof\n",
    "    with json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    log.info(f\"Updated JSON with {len(new_profiles)} new profiles\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Reload to DB (optional)\n",
    "# ----------------------------------------------------------------------\n",
    "def reload_to_db(data: Dict[str, Any]) -> None:\n",
    "    \"\"\"Re-run upsert for all data (or just failures).\"\"\"\n",
    "    import psycopg2\n",
    "    import psycopg2.extras\n",
    "\n",
    "    def ensure_table(cur):\n",
    "        cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS sp500_finnhub (\n",
    "            symbol                     VARCHAR(10) PRIMARY KEY,\n",
    "            country                    VARCHAR(100),\n",
    "            currency                   VARCHAR(10),\n",
    "            estimate_currency          VARCHAR(10),\n",
    "            exchange                   VARCHAR(255),\n",
    "            main_industry              VARCHAR(255),\n",
    "            floating_share_millions    NUMERIC,\n",
    "            market_cap_usd_millions    NUMERIC,\n",
    "            share_outstanding_millions NUMERIC,\n",
    "            ipo_date                   DATE,\n",
    "            logo                       TEXT,\n",
    "            name                       VARCHAR(255),\n",
    "            phone                      VARCHAR(50),\n",
    "            ticker                     VARCHAR(10),\n",
    "            weburl                     TEXT,\n",
    "            raw_json                   JSONB\n",
    "        );\n",
    "        \"\"\")\n",
    "\n",
    "    def upsert(cur, sym: str, prof: Dict[str, Any]):\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO sp500_finnhub (\n",
    "            symbol, country, currency, estimate_currency, exchange,\n",
    "            main_industry, floating_share_millions, market_cap_usd_millions, share_outstanding_millions,\n",
    "            ipo_date, logo, name, phone, ticker, weburl, raw_json\n",
    "        ) VALUES (\n",
    "            %(symbol)s, %(country)s, %(currency)s, %(estimateCurrency)s,\n",
    "            %(exchange)s, %(finnhubIndustry)s, %(floatingShare)s, %(marketCapitalization)s, %(shareOutstanding)s,\n",
    "            %(ipo)s::date, %(logo)s, %(name)s, %(phone)s, %(ticker)s, %(weburl)s, %(raw_json)s\n",
    "        )\n",
    "        ON CONFLICT (symbol) DO UPDATE SET\n",
    "            country=EXCLUDED.country, currency=EXCLUDED.currency, estimate_currency=EXCLUDED.estimate_currency,\n",
    "            exchange=EXCLUDED.exchange, main_industry=EXCLUDED.main_industry,\n",
    "            floating_share_millions=EXCLUDED.floating_share_millions,\n",
    "            market_cap_usd_millions=EXCLUDED.market_cap_usd_millions,\n",
    "            share_outstanding_millions=EXCLUDED.share_outstanding_millions,\n",
    "            ipo_date=EXCLUDED.ipo_date, logo=EXCLUDED.logo, name=EXCLUDED.name,\n",
    "            phone=EXCLUDED.phone, ticker=EXCLUDED.ticker, weburl=EXCLUDED.weburl,\n",
    "            raw_json=EXCLUDED.raw_json;\n",
    "        \"\"\", {\n",
    "            \"symbol\": sym, \"country\": prof.get(\"country\"), \"currency\": prof.get(\"currency\"),\n",
    "            \"estimateCurrency\": prof.get(\"estimateCurrency\"), \"exchange\": prof.get(\"exchange\"),\n",
    "            \"finnhubIndustry\": prof.get(\"finnhubIndustry\"), \"floatingShare\": prof.get(\"floatingShare\"),\n",
    "            \"marketCapitalization\": prof.get(\"marketCapitalization\"), \"shareOutstanding\": prof.get(\"shareOutstanding\"),\n",
    "            \"ipo\": prof.get(\"ipo\"), \"logo\": prof.get(\"logo\"), \"name\": prof.get(\"name\"),\n",
    "            \"phone\": prof.get(\"phone\"), \"ticker\": prof.get(\"ticker\"), \"weburl\": prof.get(\"weburl\"),\n",
    "            \"raw_json\": psycopg2.extras.Json(prof)\n",
    "        })\n",
    "\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    ensure_table(cur)\n",
    "    for sym, prof in data.items():\n",
    "        if prof:  # Only upsert non-empty\n",
    "            upsert(cur, sym, prof)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    log.info(\"Re-loaded all data to PostgreSQL\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Main\n",
    "# ----------------------------------------------------------------------\n",
    "def main() -> None:\n",
    "    data, json_path = load_json()\n",
    "    failures = find_failures(data)\n",
    "    if not failures:\n",
    "        log.info(\"No failures found – all good!\")\n",
    "        return\n",
    "\n",
    "    save_failed_list(failures)\n",
    "\n",
    "    new_profiles = {}\n",
    "    for sym in failures:\n",
    "        log.info(f\"Refetching {sym}\")\n",
    "        prof = finnhub_profile(sym)\n",
    "        new_profiles[sym] = prof\n",
    "        if prof:\n",
    "            log.info(f\"Success: {sym} → {prof.get('name', 'No name')}\")\n",
    "        else:\n",
    "            log.warning(f\"Still failed: {sym}\")\n",
    "        time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    if UPDATE_JSON:\n",
    "        update_json(data, json_path, new_profiles)\n",
    "\n",
    "    if RELOAD_DB:\n",
    "        reload_to_db(data)\n",
    "\n",
    "    log.info(\"Refetch complete! Check failed_symbols.txt for any remaining issues.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
